{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDss+r56qSRtS1pZhkFjXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh1nysparkly/relevance-validation/blob/main/NLP_KW_Prio_Validator_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "KEYWORD ARRANGEMENT OPTIMIZER\n",
        "==============================\n",
        "Upload a CSV with your keywords and test different arrangements to find\n",
        "which produces the strongest topical signal from Google's NLP API.\n",
        "\n",
        "YOUR CSV FORMAT:\n",
        "- Slug (page name)\n",
        "- Keyword\n",
        "- Search Volume\n",
        "- Priority (Primary, Secondary, or Tertiary)\n",
        "\n",
        "STEPS:\n",
        "1. Run the setup cell\n",
        "2. Upload your CSV when prompted\n",
        "3. Enter your target category when prompted\n",
        "4. Review results!\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: INSTALL & IMPORT\n",
        "# ============================================================================\n",
        "\n",
        "!pip install google-cloud-language pandas -q\n",
        "\n",
        "from google.cloud import language_v1\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAyifWIOy7kg",
        "outputId": "922538ce-d8d6-4adc-ac6c-d4a704b7ea42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: AUTHENTICATE WITH GOOGLE CLOUD\n",
        "# ============================================================================\n",
        "\n",
        "# Option B: Upload service account JSON file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = list(uploaded.keys())[0]\n",
        "\n",
        "print(\"‚úÖ Libraries loaded and authenticated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "UkKIQaKty9pC",
        "outputId": "5884fe81-465f-45d1-970a-63bd07b8dc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e518081f-2814-4c9c-9a7a-a0ce3eb7146e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e518081f-2814-4c9c-9a7a-a0ce3eb7146e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nlp-entity-detection-79a294e928f3.json to nlp-entity-detection-79a294e928f3.json\n",
            "‚úÖ Libraries loaded and authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: UPLOAD YOUR KEYWORDS CSV\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üì§ UPLOAD YOUR KEYWORDS CSV\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "Your CSV should have columns:\n",
        "- Slug (page identifier)\n",
        "- Keyword (the actual keyword)\n",
        "- Search Volume (monthly volume)\n",
        "- Priority (Primary, Secondary, or Tertiary)\n",
        "\n",
        "Upload your file now:\n",
        "\"\"\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"‚ùå No file uploaded - stopping here\")\n",
        "    raise Exception(\"Please upload a CSV file\")\n",
        "\n",
        "# Load the CSV\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded {len(df)} keywords from {filename}\")\n",
        "print(f\"\\nColumns found: {list(df.columns)}\")\n",
        "print(f\"\\nFirst 3 rows:\")\n",
        "print(df.head(3).to_string(index=False))\n",
        "\n",
        "# Check for required columns (with flexible naming)\n",
        "required_cols = {\n",
        "    'slug': ['slug', 'page', 'url', 'page_name'],\n",
        "    'keyword': ['keyword', 'keywords', 'term'],\n",
        "    'volume': ['search volume', 'volume', 'search_volume', 'sv'],\n",
        "    'priority': ['priority', 'tier', 'recommendation', 'level']\n",
        "}\n",
        "\n",
        "# Map user's columns to standard names\n",
        "col_mapping = {}\n",
        "for standard_name, possible_names in required_cols.items():\n",
        "    found = False\n",
        "    for col in df.columns:\n",
        "        if col.lower() in possible_names:\n",
        "            col_mapping[standard_name] = col\n",
        "            found = True\n",
        "            break\n",
        "    if not found and standard_name in ['slug', 'keyword']:\n",
        "        print(f\"‚ùå Required column '{standard_name}' not found\")\n",
        "        print(f\"   Expected one of: {', '.join(possible_names)}\")\n",
        "        raise Exception(f\"Missing required column: {standard_name}\")\n",
        "\n",
        "# Rename columns to standard names\n",
        "df_renamed = df.rename(columns={v: k for k, v in col_mapping.items()})\n",
        "\n",
        "# Get unique pages\n",
        "unique_pages = df_renamed['slug'].unique()\n",
        "\n",
        "print(f\"\\n‚úÖ Found {len(unique_pages)} unique pages:\")\n",
        "for i, page in enumerate(unique_pages[:10], 1):\n",
        "    count = len(df_renamed[df_renamed['slug'] == page])\n",
        "    print(f\"   {i}. {page} ({count} keywords)\")\n",
        "if len(unique_pages) > 10:\n",
        "    print(f\"   ... and {len(unique_pages) - 10} more\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "9vRNyFg1y_kB",
        "outputId": "955dcb01-0d78-43e0-fd56-fc3aa6518308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üì§ UPLOAD YOUR KEYWORDS CSV\n",
            "================================================================================\n",
            "\n",
            "Your CSV should have columns:\n",
            "- Slug (page identifier)\n",
            "- Keyword (the actual keyword)\n",
            "- Search Volume (monthly volume)\n",
            "- Priority (Primary, Secondary, or Tertiary)\n",
            "\n",
            "Upload your file now:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3bb34718-65a9-426f-a69a-6d9f6c6e9fb3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3bb34718-65a9-426f-a69a-6d9f6c6e9fb3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving family vacation packages test.csv to family vacation packages test (1).csv\n",
            "\n",
            "‚úÖ Loaded 394 keywords from family vacation packages test (1).csv\n",
            "\n",
            "Columns found: ['Slug', 'Keyword', 'Search Volume', 'Priority']\n",
            "\n",
            "First 3 rows:\n",
            "                               Slug                   Keyword  Search Volume Priority\n",
            "/vacation-packages/corporate-travel travel incentive programs           20.0  Primary\n",
            "/vacation-packages/corporate-travel incentive travel programs           10.0  Primary\n",
            "/vacation-packages/corporate-travel          incentive travel          150.0  Primary\n",
            "\n",
            "‚úÖ Found 19 unique pages:\n",
            "   1. /vacation-packages/corporate-travel (13 keywords)\n",
            "   2. /vacation-packages/destination-weddings (42 keywords)\n",
            "   3. /vacation-packages/honeymoons (38 keywords)\n",
            "   4. /vacation-packages/adventure (34 keywords)\n",
            "   5. /vacation-packages/long-stay (31 keywords)\n",
            "   6. /vacation-packages/beach (29 keywords)\n",
            "   7. /vacation-packages/theme-parks (17 keywords)\n",
            "   8. /vacation-packages/family (32 keywords)\n",
            "   9. /things-to-do/family (17 keywords)\n",
            "   10. /things-to-do/friends (23 keywords)\n",
            "   ... and 9 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: SELECT PAGE TO TEST\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ SELECT PAGE TO TEST\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Show numbered list\n",
        "print(\"\\nAvailable pages:\")\n",
        "for i, page in enumerate(unique_pages, 1):\n",
        "    count = len(df_renamed[df_renamed['slug'] == page])\n",
        "    print(f\"{i}. {page} ({count} keywords)\")\n",
        "\n",
        "# Get user selection\n",
        "page_number = input(f\"\\nEnter page number to test (1-{len(unique_pages)}): \")\n",
        "try:\n",
        "    page_idx = int(page_number) - 1\n",
        "    selected_page = unique_pages[page_idx]\n",
        "    print(f\"\\n‚úÖ Selected: {selected_page}\")\n",
        "except:\n",
        "    print(\"‚ùå Invalid selection, using first page\")\n",
        "    selected_page = unique_pages[0]\n",
        "\n",
        "# Filter to selected page\n",
        "page_keywords = df_renamed[df_renamed['slug'] == selected_page].copy()\n",
        "\n",
        "print(f\"\\nüìä Keywords for {selected_page}:\")\n",
        "priority_counts = page_keywords['priority'].value_counts()\n",
        "print(priority_counts.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx42E2l_zC9W",
        "outputId": "aa26c5cb-2fad-4547-b8d9-ab7a78fc56c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üéØ SELECT PAGE TO TEST\n",
            "================================================================================\n",
            "\n",
            "Available pages:\n",
            "1. /vacation-packages/corporate-travel (13 keywords)\n",
            "2. /vacation-packages/destination-weddings (42 keywords)\n",
            "3. /vacation-packages/honeymoons (38 keywords)\n",
            "4. /vacation-packages/adventure (34 keywords)\n",
            "5. /vacation-packages/long-stay (31 keywords)\n",
            "6. /vacation-packages/beach (29 keywords)\n",
            "7. /vacation-packages/theme-parks (17 keywords)\n",
            "8. /vacation-packages/family (32 keywords)\n",
            "9. /things-to-do/family (17 keywords)\n",
            "10. /things-to-do/friends (23 keywords)\n",
            "11. /things-to-do/couples (11 keywords)\n",
            "12. /vacation-packages/couples (21 keywords)\n",
            "13. /vacation-packages/food-wine (7 keywords)\n",
            "14. /things-to-do/wine-food (9 keywords)\n",
            "15. /vacation-packages/golf-vacations-sports (22 keywords)\n",
            "16. /things-to-do/golf-sports (9 keywords)\n",
            "17. /vacation-packages/pet-friendly-travel (8 keywords)\n",
            "18. /things-to-do/pet-friendly (15 keywords)\n",
            "19. /things-to-do/accessible (16 keywords)\n",
            "\n",
            "Enter page number to test (1-19): 8\n",
            "\n",
            "‚úÖ Selected: /vacation-packages/family\n",
            "\n",
            "üìä Keywords for /vacation-packages/family:\n",
            "priority\n",
            "Tertiary     19\n",
            "Secondary     9\n",
            "Primary       4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 5: ENTER TARGET CATEGORY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ TARGET CATEGORY\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "Enter the category you want this page to be detected as.\n",
        "\n",
        "Examples:\n",
        "- Travel\n",
        "- Business\n",
        "- Food & Drink\n",
        "- Sports\n",
        "- Arts & Entertainment\n",
        "\n",
        "Common Google NLP categories:\n",
        "- /Arts & Entertainment\n",
        "- /Autos & Vehicles\n",
        "- /Beauty & Fitness\n",
        "- /Business & Industrial\n",
        "- /Computers & Electronics\n",
        "- /Finance\n",
        "- /Food & Drink\n",
        "- /Games\n",
        "- /Health\n",
        "- /Hobbies & Leisure\n",
        "- /Home & Garden\n",
        "- /Internet & Telecom\n",
        "- /Jobs & Education\n",
        "- /Law & Government\n",
        "- /News\n",
        "- /Online Communities\n",
        "- /People & Society\n",
        "- /Pets & Animals\n",
        "- /Real Estate\n",
        "- /Reference\n",
        "- /Science\n",
        "- /Shopping\n",
        "- /Sports\n",
        "- /Travel & Transportation\n",
        "\n",
        "Tip: Use broad terms like \"Travel\" - they'll match any subcategory\n",
        "Full list: https://cloud.google.com/natural-language/docs/categories\n",
        "\"\"\")\n",
        "\n",
        "target_category = input(\"Enter your target category: \")\n",
        "print(f\"\\n‚úÖ Target: {target_category}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVCOSWh9zEwB",
        "outputId": "48c3ee38-9362-4d6e-e3ce-83d33912b8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üéØ TARGET CATEGORY\n",
            "================================================================================\n",
            "\n",
            "Enter the category you want this page to be detected as.\n",
            "\n",
            "Examples:\n",
            "- Travel\n",
            "- Business\n",
            "- Food & Drink\n",
            "- Sports\n",
            "- Arts & Entertainment\n",
            "\n",
            "Common Google NLP categories:\n",
            "- /Arts & Entertainment\n",
            "- /Autos & Vehicles\n",
            "- /Beauty & Fitness\n",
            "- /Business & Industrial\n",
            "- /Computers & Electronics\n",
            "- /Finance\n",
            "- /Food & Drink\n",
            "- /Games\n",
            "- /Health\n",
            "- /Hobbies & Leisure\n",
            "- /Home & Garden\n",
            "- /Internet & Telecom\n",
            "- /Jobs & Education\n",
            "- /Law & Government\n",
            "- /News\n",
            "- /Online Communities\n",
            "- /People & Society\n",
            "- /Pets & Animals\n",
            "- /Real Estate\n",
            "- /Reference\n",
            "- /Science\n",
            "- /Shopping\n",
            "- /Sports\n",
            "- /Travel & Transportation\n",
            "\n",
            "Tip: Use broad terms like \"Travel\" - they'll match any subcategory\n",
            "Full list: https://cloud.google.com/natural-language/docs/categories\n",
            "\n",
            "Enter your target category: /Travel & Transportation/Specialty Travel/Family Travel\n",
            "\n",
            "‚úÖ Target: /Travel & Transportation/Specialty Travel/Family Travel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 6: CONTENT SIMULATION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def simulate_page_content(primary_kws, secondary_kws, tertiary_kws, brand_name=\"Your Brand\"):\n",
        "    \"\"\"\n",
        "    Matches the format from your other tool:\n",
        "    Just space-separated keywords, no fancy structure\n",
        "    \"\"\"\n",
        "    if not primary_kws:\n",
        "        return \"\"\n",
        "\n",
        "    # Combine ALL keywords with spaces (like your other tool does)\n",
        "    all_keywords = primary_kws + secondary_kws + tertiary_kws\n",
        "\n",
        "    # Just join with spaces\n",
        "    return \" \".join(all_keywords)\n"
      ],
      "metadata": {
        "id": "c3TL-Zb5zHB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 7: GOOGLE NLP ANALYSIS FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_with_google_nlp(content_text, target_category=None):\n",
        "    \"\"\"Analyze content with Google NLP API using annotate_text\"\"\"\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    document = language_v1.Document(\n",
        "        content=content_text,\n",
        "        type_=language_v1.Document.Type.PLAIN_TEXT\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Use annotate_text like the other tool\n",
        "        response = client.annotate_text(\n",
        "            document=document,\n",
        "            features={\n",
        "                'extract_entities': True,\n",
        "                'classify_text': True\n",
        "            }\n",
        "        )\n",
        "\n",
        "        categories = response.categories\n",
        "        entities = response.entities\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  NLP API error: {e}\")\n",
        "        return None\n",
        "\n",
        "    if not categories:\n",
        "        return {\n",
        "            'top_category': None,\n",
        "            'top_confidence': 0,\n",
        "            'all_categories': [],\n",
        "            'top_entities': [],\n",
        "            'matches_target': False,\n",
        "            'target_confidence': 0\n",
        "        }\n",
        "\n",
        "    # Parse entities\n",
        "    top_entities = []\n",
        "    for ent in entities[:5]:\n",
        "        try:\n",
        "            if hasattr(ent.type_, 'name'):\n",
        "                entity_type = ent.type_.name\n",
        "            else:\n",
        "                entity_type = language_v1.Entity.Type(ent.type_).name\n",
        "        except:\n",
        "            entity_type = str(ent.type_)\n",
        "        top_entities.append((ent.name, ent.salience, entity_type))\n",
        "\n",
        "    results = {\n",
        "        'top_category': categories[0].name,\n",
        "        'top_confidence': categories[0].confidence,\n",
        "        'all_categories': [(cat.name, cat.confidence) for cat in categories[:5]],\n",
        "        'top_entities': top_entities,\n",
        "        'matches_target': False,\n",
        "        'target_confidence': 0\n",
        "    }\n",
        "\n",
        "    if target_category:\n",
        "        for cat in categories:\n",
        "            if target_category.lower() in cat.name.lower():\n",
        "                results['matches_target'] = True\n",
        "                results['target_confidence'] = cat.confidence\n",
        "                results['matched_category'] = cat.name\n",
        "                break\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "Vo3_n0cszJIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 8: RUN THE TESTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"üß™ TESTING: {selected_page}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Prepare keyword list\n",
        "keyword_list = []\n",
        "for _, row in page_keywords.iterrows():\n",
        "    keyword_list.append({\n",
        "        'keyword': row['keyword'],\n",
        "        'volume': row.get('volume', 0),\n",
        "        'tier': row['priority'].lower()\n",
        "    })\n",
        "\n",
        "# Organize by tier\n",
        "primary = [kw for kw in keyword_list if 'primary' in kw['tier'].lower()]\n",
        "secondary = [kw for kw in keyword_list if 'secondary' in kw['tier'].lower()]\n",
        "tertiary = [kw for kw in keyword_list if 'tertiary' in kw['tier'].lower()]\n",
        "\n",
        "print(f\"\\nKeyword Distribution:\")\n",
        "print(f\"  Primary: {len(primary)}\")\n",
        "print(f\"  Secondary: {len(secondary)}\")\n",
        "print(f\"  Tertiary: {len(tertiary)}\")\n",
        "\n",
        "# Define test arrangements\n",
        "arrangements = [\n",
        "    {\n",
        "        'name': 'Baseline (Current)',\n",
        "        'description': 'Your current keyword arrangement',\n",
        "        'primary': [kw['keyword'] for kw in primary],\n",
        "        'secondary': [kw['keyword'] for kw in secondary],\n",
        "        'tertiary': [kw['keyword'] for kw in tertiary]\n",
        "    },\n",
        "    {\n",
        "        'name': 'Primary Focus',\n",
        "        'description': 'Only primary keywords',\n",
        "        'primary': [kw['keyword'] for kw in primary[:2]],\n",
        "        'secondary': [],\n",
        "        'tertiary': []\n",
        "    },\n",
        "    {\n",
        "        'name': 'Balanced Top Terms',\n",
        "        'description': 'Top 2 primary + top 3 secondary',\n",
        "        'primary': [kw['keyword'] for kw in primary[:2]],\n",
        "        'secondary': [kw['keyword'] for kw in secondary[:3]],\n",
        "        'tertiary': []\n",
        "    },\n",
        "]\n",
        "\n",
        "# Add swap test if applicable\n",
        "if len(primary) > 0 and len(secondary) > 0:\n",
        "    arrangements.append({\n",
        "        'name': 'Swap Primary/Secondary',\n",
        "        'description': 'Test if secondary term is stronger',\n",
        "        'primary': [secondary[0]['keyword']],\n",
        "        'secondary': [primary[0]['keyword']] + [kw['keyword'] for kw in secondary[1:3]],\n",
        "        'tertiary': []\n",
        "    })\n",
        "\n",
        "# Add high-volume test\n",
        "all_kws = primary + secondary + tertiary\n",
        "sorted_by_vol = sorted(all_kws, key=lambda x: x.get('volume', 0), reverse=True)\n",
        "arrangements.append({\n",
        "    'name': 'High-Volume Focus',\n",
        "    'description': 'Prioritize highest volume',\n",
        "    'primary': [sorted_by_vol[0]['keyword']],\n",
        "    'secondary': [kw['keyword'] for kw in sorted_by_vol[1:4]],\n",
        "    'tertiary': []\n",
        "})\n",
        "\n",
        "arrangements.append({\n",
        "    'name': 'All-In (Full Coverage)',\n",
        "    'description': 'Include all keywords',\n",
        "    'primary': [kw['keyword'] for kw in primary],\n",
        "    'secondary': [kw['keyword'] for kw in secondary],\n",
        "    'tertiary': [kw['keyword'] for kw in tertiary]  # Remove the [:5] cap\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy1e2vuk7xBe",
        "outputId": "496569c2-6214-474e-e58e-2d211a611729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üß™ TESTING: /vacation-packages/family\n",
            "================================================================================\n",
            "\n",
            "Keyword Distribution:\n",
            "  Primary: 4\n",
            "  Secondary: 9\n",
            "  Tertiary: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the test loop, RIGHT BEFORE calling analyze_with_google_nlp, add this:\n",
        "\n",
        "for i, arrangement in enumerate(arrangements, 1):\n",
        "    print(f\"\\nüî¨ Test {i}/{len(arrangements)}: {arrangement['name']}\")\n",
        "\n",
        "    content = simulate_page_content(\n",
        "        arrangement['primary'],\n",
        "        arrangement['secondary'],\n",
        "        arrangement['tertiary']\n",
        "    )\n",
        "\n",
        "    # ADD THIS DEBUG OUTPUT:\n",
        "    print(f\"   DEBUG - Content length: {len(content)} chars, {len(content.split())} words\")\n",
        "    print(f\"   DEBUG - First 100 chars: {content[:100]}\")\n",
        "\n",
        "    if not content:\n",
        "        continue\n",
        "\n",
        "    nlp_result = analyze_with_google_nlp(content, target_category)\n",
        "    # ... rest of code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hsKLqk676Kl",
        "outputId": "16372337-2beb-4828-ca1a-aca1f50e54b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî¨ Test 1/6: Baseline (Current)\n",
            "   DEBUG - Content length: 990 chars, 128 words\n",
            "   DEBUG - First 100 chars: family vacations family vacation specials all inclusive all inclusive family vacation packages famil\n",
            "\n",
            "üî¨ Test 2/6: Primary Focus\n",
            "   DEBUG - Content length: 55 chars, 7 words\n",
            "   DEBUG - First 100 chars: family vacations family vacation specials all inclusive\n",
            "‚ö†Ô∏è  NLP API error: 400 Invalid text content: too few tokens (words) to process. [field_violations {\n",
            "  field: \"document\"\n",
            "  description: \"Invalid text content: too few tokens (words) to process.\"\n",
            "}\n",
            "]\n",
            "\n",
            "üî¨ Test 3/6: Balanced Top Terms\n",
            "   DEBUG - Content length: 120 chars, 16 words\n",
            "   DEBUG - First 100 chars: family vacations family vacation specials all inclusive family vacation packages family resorts all \n",
            "‚ö†Ô∏è  NLP API error: 400 Invalid text content: too few tokens (words) to process. [field_violations {\n",
            "  field: \"document\"\n",
            "  description: \"Invalid text content: too few tokens (words) to process.\"\n",
            "}\n",
            "]\n",
            "\n",
            "üî¨ Test 4/6: Swap Primary/Secondary\n",
            "   DEBUG - Content length: 81 chars, 11 words\n",
            "   DEBUG - First 100 chars: family vacation packages family vacations family resorts all inclusive for family\n",
            "‚ö†Ô∏è  NLP API error: 400 Invalid text content: too few tokens (words) to process. [field_violations {\n",
            "  field: \"document\"\n",
            "  description: \"Invalid text content: too few tokens (words) to process.\"\n",
            "}\n",
            "]\n",
            "\n",
            "üî¨ Test 5/6: High-Volume Focus\n",
            "   DEBUG - Content length: 156 chars, 21 words\n",
            "   DEBUG - First 100 chars: great all inclusive vacations for families mexico all inclusive vacations family mexico vacations fa\n",
            "\n",
            "üî¨ Test 6/6: All-In (Full Coverage)\n",
            "   DEBUG - Content length: 990 chars, 128 words\n",
            "   DEBUG - First 100 chars: family vacations family vacation specials all inclusive all inclusive family vacation packages famil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests\n",
        "results = []\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Running NLP Analysis...\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "for i, arrangement in enumerate(arrangements, 1):\n",
        "    print(f\"\\nüî¨ Test {i}/{len(arrangements)}: {arrangement['name']}\")\n",
        "\n",
        "    content = simulate_page_content(\n",
        "        arrangement['primary'],\n",
        "        arrangement['secondary'],\n",
        "        arrangement['tertiary']\n",
        "    )\n",
        "\n",
        "    if not content:\n",
        "        continue\n",
        "\n",
        "    nlp_result = analyze_with_google_nlp(content, target_category)\n",
        "\n",
        "    if not nlp_result:\n",
        "        continue\n",
        "\n",
        "    result = {\n",
        "        'arrangement': arrangement['name'],\n",
        "        'description': arrangement['description'],\n",
        "        'primary_kws': arrangement['primary'][:3],\n",
        "        'num_primary': len(arrangement['primary']),\n",
        "        'num_secondary': len(arrangement['secondary']),\n",
        "        'num_tertiary': len(arrangement['tertiary']),\n",
        "        'detected_category': nlp_result['top_category'],\n",
        "        'confidence': nlp_result['top_confidence'],\n",
        "        'matches_target': nlp_result['matches_target'],\n",
        "        'target_confidence': nlp_result['target_confidence'],\n",
        "        'matched_category': nlp_result.get('matched_category', 'N/A'),\n",
        "        'all_categories': nlp_result['all_categories'][:3],\n",
        "        'top_entities': nlp_result['top_entities'][:3]\n",
        "    }\n",
        "    results.append(result)\n",
        "\n",
        "    print(f\"   Primary: {', '.join(result['primary_kws'])}\")\n",
        "    print(f\"   Detected: {result['detected_category']}\")\n",
        "    print(f\"   Confidence: {result['confidence']:.1%}\")\n",
        "    if result['matches_target']:\n",
        "        print(f\"   ‚úÖ MATCHES target! ({result['target_confidence']:.1%})\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Does NOT match target\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-4t9koTzK81",
        "outputId": "9d1f8716-0139-4b41-c3fb-cc3de7b184f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Running NLP Analysis...\n",
            "================================================================================\n",
            "\n",
            "üî¨ Test 1/6: Baseline (Current)\n",
            "   Primary: family vacations, family vacation specials all inclusive, all inclusive family vacation packages\n",
            "   Detected: /Travel\n",
            "   Confidence: 99.0%\n",
            "   ‚ùå Does NOT match target\n",
            "\n",
            "üî¨ Test 2/6: Primary Focus\n",
            "‚ö†Ô∏è  NLP API error: 400 Invalid text content: too few tokens (words) to process. [field_violations {\n",
            "  field: \"document\"\n",
            "  description: \"Invalid text content: too few tokens (words) to process.\"\n",
            "}\n",
            "]\n",
            "\n",
            "üî¨ Test 3/6: Balanced Top Terms\n",
            "‚ö†Ô∏è  NLP API error: 400 Invalid text content: too few tokens (words) to process. [field_violations {\n",
            "  field: \"document\"\n",
            "  description: \"Invalid text content: too few tokens (words) to process.\"\n",
            "}\n",
            "]\n",
            "\n",
            "üî¨ Test 4/6: Swap Primary/Secondary\n",
            "‚ö†Ô∏è  NLP API error: 400 Invalid text content: too few tokens (words) to process. [field_violations {\n",
            "  field: \"document\"\n",
            "  description: \"Invalid text content: too few tokens (words) to process.\"\n",
            "}\n",
            "]\n",
            "\n",
            "üî¨ Test 5/6: High-Volume Focus\n",
            "   Primary: great all inclusive vacations for families\n",
            "   Detected: /Travel\n",
            "   Confidence: 99.0%\n",
            "   ‚ùå Does NOT match target\n",
            "\n",
            "üî¨ Test 6/6: All-In (Full Coverage)\n",
            "   Primary: family vacations, family vacation specials all inclusive, all inclusive family vacation packages\n",
            "   Detected: /Travel\n",
            "   Confidence: 99.0%\n",
            "   ‚ùå Does NOT match target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMBi8GiFy4EP",
        "outputId": "4fa265b1-7c8e-46a5-d7cd-f383773d19bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "           Arrangement Match Target Overall    KWs\n",
            "    Baseline (Current)     ‚ùå   0.0%   99.0% 4/9/19\n",
            "    Balanced Top Terms     ‚ùå   0.0%   99.0%  2/3/0\n",
            "     High-Volume Focus     ‚ùå   0.0%   99.0%  1/3/0\n",
            "All-In (Full Coverage)     ‚ùå   0.0%   99.0% 4/9/19\n",
            "\n",
            "================================================================================\n",
            "üèÜ RECOMMENDED: Baseline (Current)\n",
            "================================================================================\n",
            "Your current keyword arrangement\n",
            "\n",
            "Primary (4): family vacations, family vacation specials all inclusive, all inclusive family vacation packages\n",
            "Secondary: 9\n",
            "Tertiary: 19\n",
            "\n",
            "Detected: /Travel\n",
            "Confidence: 99.0%\n",
            "\n",
            "Top Entities:\n",
            "  ‚Ä¢ family vacations (salience: 0.34, type: EVENT)\n",
            "  ‚Ä¢ family vacations (salience: 0.18, type: EVENT)\n",
            "  ‚Ä¢ family vacation specials (salience: 0.11, type: OTHER)\n",
            "\n",
            "‚úÖ Exported results to arrangement_results__vacation-packages_family.csv\n",
            "\n",
            "================================================================================\n",
            "‚úÖ COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 9: SHOW RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "if not results:\n",
        "    print(\"\\n‚ùå No results generated\")\n",
        "else:\n",
        "    best = max(results, key=lambda x: (x['target_confidence'], x['confidence']))\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"üìä RESULTS SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    results_df = pd.DataFrame([{\n",
        "        'Arrangement': r['arrangement'],\n",
        "        'Match': '‚úÖ' if r['matches_target'] else '‚ùå',\n",
        "        'Target': f\"{r['target_confidence']:.1%}\",\n",
        "        'Overall': f\"{r['confidence']:.1%}\",\n",
        "        'KWs': f\"{r['num_primary']}/{r['num_secondary']}/{r['num_tertiary']}\"\n",
        "    } for r in results])\n",
        "\n",
        "    print(\"\\n\" + results_df.to_string(index=False))\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üèÜ RECOMMENDED: {best['arrangement']}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"{best['description']}\")\n",
        "    print(f\"\\nPrimary ({best['num_primary']}): {', '.join(best['primary_kws'])}\")\n",
        "    print(f\"Secondary: {best['num_secondary']}\")\n",
        "    print(f\"Tertiary: {best['num_tertiary']}\")\n",
        "    print(f\"\\nDetected: {best['detected_category']}\")\n",
        "    print(f\"Confidence: {best['confidence']:.1%}\")\n",
        "    if best['matches_target']:\n",
        "        print(f\"‚úÖ Target Match: {best['matched_category']} ({best['target_confidence']:.1%})\")\n",
        "\n",
        "    print(f\"\\nTop Entities:\")\n",
        "    for entity, salience, ent_type in best['top_entities']:\n",
        "        print(f\"  ‚Ä¢ {entity} (salience: {salience:.2f}, type: {ent_type})\")\n",
        "\n",
        "    # Export\n",
        "    results_export = pd.DataFrame(results)\n",
        "    results_export.to_csv(f'arrangement_results_{selected_page.replace(\"/\", \"_\")}.csv', index=False)\n",
        "    print(f\"\\n‚úÖ Exported results to arrangement_results_{selected_page.replace('/', '_')}.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ COMPLETE!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ]
}