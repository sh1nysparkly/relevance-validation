{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPFQBhsxJohfHFPUqKGTVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh1nysparkly/relevance-validation/blob/main/NLP_Page_Title_Meta_Content_Block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Content Draft NLP Analyzer (v2)\n",
        "\n",
        "This script takes a CSV of draft content, runs it through the Google NLP API,\n",
        "and generates four output files for detailed analysis:\n",
        "1. pages_summary.csv: A high-level overview of each page.\n",
        "2. entities.csv: A detailed, one-row-per-entity breakdown.\n",
        "3. categories.csv: A detailed, one-row-per-category breakdown.\n",
        "4. content_draft_analysis.json: The full raw data in a nested format.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import files\n",
        "from google.cloud import language_v1\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "D0nhj1ipLL7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. File Uploads ---\n",
        "print(\"\\nüîë Upload your Google Cloud service account JSON key:\")\n",
        "key_uploaded = files.upload()\n",
        "key_filename = list(key_uploaded.keys())[0]\n",
        "print(f\"‚úÖ Loaded credentials: {key_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "wPqNfgXHPk3f",
        "outputId": "57836c64-8a58-4814-faa2-75ece03f5103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîë Upload your Google Cloud service account JSON key:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8d131a7-84be-4d90-ba1d-473ebaecf0de\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8d131a7-84be-4d90-ba1d-473ebaecf0de\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nlp-entity-detection-79a294e928f3.json to nlp-entity-detection-79a294e928f3 (8).json\n",
            "‚úÖ Loaded credentials: nlp-entity-detection-79a294e928f3 (8).json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìÅ Upload your CSV file with content drafts:\")\n",
        "print(\"   (It needs columns: 'page_identifier', 'page_title', 'meta_description', 'body_copy')\")\n",
        "uploaded = files.upload()\n",
        "csv_filename = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Loaded: {csv_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "t-_7WvBiNDPO",
        "outputId": "e6df8b9f-9f13-4c49-be41-6f69742f0414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Upload your CSV file with content drafts:\n",
            "   (It needs columns: 'page_identifier', 'page_title', 'meta_description', 'body_copy')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3bbfa87e-9024-4d82-bf1f-ea9e9883aeb6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3bbfa87e-9024-4d82-bf1f-ea9e9883aeb6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving copy_input_templated.csv to copy_input_templated (6).csv\n",
            "‚úÖ Loaded: copy_input_templated (6).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2 Authentication ---\n",
        "# This assumes 'key_filename' and 'csv_filename' are already defined from the previous cell\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_filename\n",
        "client = language_v1.LanguageServiceClient()\n",
        "\n",
        "print(f\"\\nLoading data from {csv_filename}...\")\n",
        "try:\n",
        "    # THE FIX: 'utf-8-sig' is specifically designed to handle the BOM ('√Ø¬ª¬ø')\n",
        "    content_df = pd.read_csv(csv_filename, encoding='utf-8-sig')\n",
        "    print(\"‚úÖ Successfully loaded CSV and handled BOM.\")\n",
        "\n",
        "    print(\"\\nüïµÔ∏è  Headers as read from file:\")\n",
        "    print(list(content_df.columns))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load CSV. Error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Ensure we handle empty cells gracefully\n",
        "if not content_df.empty:\n",
        "    content_df = content_df.fillna('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osnen6V0NYwK",
        "outputId": "0c0efee1-0ad8-4640-af08-70706f7ab669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading data from copy_input_templated (6).csv...\n",
            "‚úÖ Successfully loaded CSV and handled BOM.\n",
            "\n",
            "üïµÔ∏è  Headers as read from file:\n",
            "['page_identifier', 'page_title', 'meta_description', 'body_copy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. The Core NLP Analysis Function (Upgraded for Total Mentions Count) ---\n",
        "def analyze_text_content(text):\n",
        "    if not text or text.strip() == '':\n",
        "        return { 'categories': [], 'entities': [], 'error': 'Input text was empty.' }\n",
        "\n",
        "    try:\n",
        "        document = language_v1.Document(\n",
        "            content=text,\n",
        "            type_=language_v1.Document.Type.HTML\n",
        "        )\n",
        "        features = {'extract_entities': True, 'classify_text': True}\n",
        "        response = client.annotate_text(\n",
        "            document=document,\n",
        "            features=features,\n",
        "            encoding_type=language_v1.EncodingType.UTF8\n",
        "        )\n",
        "\n",
        "        categories = [{\n",
        "            'name': category.name,\n",
        "            'confidence': round(category.confidence, 4)\n",
        "        } for category in response.categories]\n",
        "        categories.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "        entities = []\n",
        "        for entity in response.entities:\n",
        "            # Get the full list of all mention texts\n",
        "            all_mentions_text = [mention.text.content for mention in entity.mentions]\n",
        "\n",
        "            # NEW: Capture both the unique list and the total count\n",
        "            unique_mentions_list = list(set(all_mentions_text))\n",
        "            total_mentions_count = len(all_mentions_text)\n",
        "\n",
        "            entities.append({\n",
        "                'name': entity.name,\n",
        "                'type': language_v1.Entity.Type(entity.type_).name,\n",
        "                'salience': round(entity.salience, 4),\n",
        "                'wikipedia_url': entity.metadata.get('wikipedia_url', ''),\n",
        "                'mid': entity.metadata.get('mid', ''),\n",
        "                'unique_mentions_list': unique_mentions_list,\n",
        "                'total_mentions_count': total_mentions_count\n",
        "            })\n",
        "        entities.sort(key=lambda x: x['salience'], reverse=True)\n",
        "\n",
        "        return { 'categories': categories, 'entities': entities, 'error': None }\n",
        "    except Exception as e:\n",
        "        return { 'categories': [], 'entities': [], 'error': str(e) }\n"
      ],
      "metadata": {
        "id": "BD6Be3X3Nb5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Main Processing Loop ---\n",
        "print(f\"\\nüöÄ Processing {len(content_df)} content drafts...\")\n",
        "analysis_results = []\n",
        "for index, row in content_df.iterrows():\n",
        "    identifier = row['page_identifier']\n",
        "    print(f\"  Analyzing: {identifier} ({index + 1}/{len(content_df)})...\")\n",
        "\n",
        "    combined_text = f\"<h1>{row['page_title']}</h1> <p>{row['meta_description']}</p> {row['body_copy']}\"\n",
        "    result = analyze_text_content(combined_text)\n",
        "\n",
        "    analysis_results.append({\n",
        "        'page_identifier': identifier,\n",
        "        'char_count': len(combined_text),\n",
        "        'detected_categories': result['categories'],\n",
        "        'detected_entities': result['entities'],\n",
        "        'error': result['error']\n",
        "    })\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(\"\\n‚úÖ NLP analysis complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6cAUXTSNeYi",
        "outputId": "3855e346-6553-4bf3-ec23-59a854e7a533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Processing 1 content drafts...\n",
            "  Analyzing: /articles/ultimate-5-day-toronto-travel-guide (1/1)...\n",
            "\n",
            "‚úÖ NLP analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Data Structuring for CSV Outputs (with two mention columns) ---\n",
        "print(\"\\nüìä Preparing data for CSV export...\")\n",
        "pages_summary_data = []\n",
        "entities_data = []\n",
        "categories_data = []\n",
        "for result in analysis_results:\n",
        "    page_id = result['page_identifier']\n",
        "    entities = result['detected_entities']\n",
        "    categories = result['detected_categories']\n",
        "\n",
        "    pages_summary_data.append({\n",
        "        'page_identifier': page_id,\n",
        "        'char_count': result['char_count'],\n",
        "        'entity_count': len(entities),\n",
        "        'category_count': len(categories),\n",
        "        'top_entities': ', '.join([e['name'] for e in entities[:5]]),\n",
        "        'top_categories': ', '.join([c['name'] for c in categories[:3]])\n",
        "    })\n",
        "\n",
        "    for entity in entities:\n",
        "        # MODIFIED: Add separate columns for the unique list and the total count\n",
        "        entities_data.append({\n",
        "            'page_identifier': page_id,\n",
        "            'entity': entity['name'],\n",
        "            'type': entity['type'],\n",
        "            'salience': entity['salience'],\n",
        "            'unique_mentions': ' | '.join(entity['unique_mentions_list']),\n",
        "            'total_mentions': entity['total_mentions_count'],\n",
        "            'wikipedia_url': entity['wikipedia_url'],\n",
        "            'mid': entity['mid']\n",
        "        })\n",
        "\n",
        "    for category in categories:\n",
        "        categories_data.append({\n",
        "            'page_identifier': page_id,\n",
        "            'category': category['name'],\n",
        "            'confidence': category['confidence']\n",
        "        })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyKWHBCBNQmv",
        "outputId": "37c3eb93-aa02-4582-bcef-bb177477181f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Preparing data for CSV export...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Save All Output Files ---\n",
        "pages_summary_df = pd.DataFrame(pages_summary_data)\n",
        "entities_df = pd.DataFrame(entities_data)\n",
        "categories_df = pd.DataFrame(categories_data)\n",
        "\n",
        "summary_filename, entities_filename, categories_filename, json_filename = 'pages_summary.csv', 'entities.csv', 'categories.csv', 'content_draft_analysis.json'\n",
        "\n",
        "pages_summary_df.to_csv(summary_filename, index=False)\n",
        "print(f\"  - Saved {summary_filename}\")\n",
        "entities_df.to_csv(entities_filename, index=False)\n",
        "print(f\"  - Saved {entities_filename}\")\n",
        "categories_df.to_csv(categories_filename, index=False)\n",
        "print(f\"  - Saved {categories_filename}\")\n",
        "\n",
        "output_json = {\n",
        "    \"metadata\": { \"total_documents_analyzed\": len(content_df), \"source_file\": csv_filename },\n",
        "    \"analysis\": analysis_results\n",
        "}\n",
        "with open(json_filename, 'w') as f:\n",
        "    json.dump(output_json, f, indent=2)\n",
        "print(f\"  - Saved {json_filename}\")\n",
        "\n",
        "# --- 7. Download All Files ---\n",
        "print(\"\\n‚¨áÔ∏è Downloading your analysis files...\")\n",
        "files.download(summary_filename)\n",
        "files.download(entities_filename)\n",
        "files.download(categories_filename)\n",
        "files.download(json_filename)\n",
        "\n",
        "print(\"\\n‚ú® All done! Check your downloads folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "ep2LpbfqfHSE",
        "outputId": "80ef2641-b1f9-4453-85b9-04bd71fb76e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Saved pages_summary.csv\n",
            "  - Saved entities.csv\n",
            "  - Saved categories.csv\n",
            "  - Saved content_draft_analysis.json\n",
            "\n",
            "‚¨áÔ∏è Downloading your analysis files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5a080d07-ef2e-42e9-8913-28b90a7300fe\", \"pages_summary.csv\", 216)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cbe89b67-6150-4032-b4a0-d5ada8ee3734\", \"entities.csv\", 22387)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_56743085-3dd9-446f-b5e0-057e4ab6ef99\", \"categories.csv\", 95)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_897d3b29-0038-4d77-98e2-93006f03b940\", \"content_draft_analysis.json\", 68568)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® All done! Check your downloads folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AHHHhHHHHHH"
      ],
      "metadata": {
        "id": "VtHVwJI6NVvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Authentication & Setup ---\n",
        "\n",
        "# This assumes 'key_filename' and 'csv_filename' are already defined from the previous cell\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_filename\n",
        "client = language_v1.LanguageServiceClient()\n",
        "\n",
        "print(f\"\\nLoading data from {csv_filename}...\")\n",
        "try:\n",
        "    # We'll try a few common encodings to be safe\n",
        "    content_df = pd.read_csv(csv_filename, encoding='latin1')\n",
        "    print(\"‚úÖ Successfully loaded CSV with 'latin1' encoding.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed with 'latin1', trying 'windows-1252'... Error: {e}\")\n",
        "    try:\n",
        "        content_df = pd.read_csv(csv_filename, encoding='windows-1252')\n",
        "        print(\"‚úÖ Successfully loaded CSV with 'windows-1252' encoding.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load CSV with common encodings. Please check the file. Error: {e}\")\n",
        "        content_df = pd.DataFrame() # Create empty dataframe to avoid further errors\n",
        "\n",
        "# Ensure we handle empty cells gracefully\n",
        "if not content_df.empty:\n",
        "    content_df = content_df.fillna('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRb8z0HsLOtl",
        "outputId": "83866b71-c0d2-4646-d05b-8b41dcfa2dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading data from copy_input_templated.csv...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. The Core NLP Analysis Function ---\n",
        "def analyze_text_content(text):\n",
        "    \"\"\"\n",
        "    Analyzes a block of text with Google NLP API.\n",
        "    Returns ALL categories and ALL entities.\n",
        "    \"\"\"\n",
        "    if not text or text.strip() == '':\n",
        "        return { 'categories': [], 'entities': [], 'error': 'Input text was empty.' }\n",
        "\n",
        "    try:\n",
        "        document = language_v1.Document(\n",
        "            content=text,\n",
        "            type_=language_v1.Document.Type.PLAIN_TEXT\n",
        "        )\n",
        "        features = { 'extract_entities': True, 'classify_text': True }\n",
        "        response = client.annotate_text(document=document, features=features)\n",
        "\n",
        "        # Extract ALL categories with confidence\n",
        "        categories = [{\n",
        "            'name': category.name,\n",
        "            'confidence': round(category.confidence, 4)\n",
        "        } for category in response.categories]\n",
        "        categories.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "        # Extract ALL entities with salience\n",
        "        # Note: We are NOT limiting the number of entities here\n",
        "        entities = [{\n",
        "            'name': entity.name,\n",
        "            'type': language_v1.Entity.Type(entity.type_).name,\n",
        "            'salience': round(entity.salience, 4)\n",
        "        } for entity in response.entities]\n",
        "        entities.sort(key=lambda x: x['salience'], reverse=True)\n",
        "\n",
        "        return { 'categories': categories, 'entities': entities, 'error': None }\n",
        "\n",
        "    except Exception as e:\n",
        "        return { 'categories': [], 'entities': [], 'error': str(e) }\n",
        "\n",
        "# --- 4. Main Processing Loop ---\n",
        "print(f\"\\nProcessing {len(content_df)} content drafts...\")\n",
        "analysis_results = []\n",
        "\n",
        "for index, row in content_df.iterrows():\n",
        "    identifier = row['page_identifier']\n",
        "    print(f\"  Analyzing: {identifier} ({index + 1}/{len(content_df)})...\")\n",
        "\n",
        "    # Combine all text fields for the most complete context\n",
        "    combined_text = f\"{row['page_title']}. {row['meta_description']}. {row['body_copy']}\"\n",
        "\n",
        "    # Analyze the text\n",
        "    result = analyze_text_content(combined_text)\n",
        "\n",
        "    # Store the results\n",
        "    analysis_results.append({\n",
        "        'page_identifier': identifier,\n",
        "        'detected_categories': result['categories'],\n",
        "        'detected_entities': result['entities'],\n",
        "        'error': result['error']\n",
        "    })\n",
        "    time.sleep(0.5) # Be a good citizen to the API\n",
        "\n",
        "print(\"\\n‚úÖ NLP analysis complete!\")\n",
        "\n",
        "# --- 5. Output Generation ---\n",
        "# Create the final output object\n",
        "output = {\n",
        "    \"metadata\": {\n",
        "        \"total_documents_analyzed\": len(content_df),\n",
        "        \"source_file\": csv_filename\n",
        "    },\n",
        "    \"analysis\": analysis_results\n",
        "}\n",
        "\n",
        "# Save the detailed JSON file\n",
        "output_filename = 'content_draft_analysis.json'\n",
        "with open(output_filename, 'w') as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "print(f\"\\nüéØ Created detailed results file: {output_filename}\")\n",
        "\n",
        "# Print a summary to the screen for quick review\n",
        "print(\"\\nüìä Quick Summary:\")\n",
        "for result in analysis_results:\n",
        "    print(f\"\\n--- Page: {result['page_identifier']} ---\")\n",
        "    if result['error']:\n",
        "        print(f\"  ‚ö†Ô∏è Error: {result['error']}\")\n",
        "        continue\n",
        "\n",
        "    # Show top 3 categories\n",
        "    top_cats = result['detected_categories'][:3]\n",
        "    if top_cats:\n",
        "        print(\"  Top Categories:\")\n",
        "        for cat in top_cats:\n",
        "            print(f\"    - {cat['name']} (Confidence: {cat['confidence']:.2%})\")\n",
        "    else:\n",
        "        print(\"  No categories detected.\")\n",
        "\n",
        "    # Show top 5 entities\n",
        "    top_ents = result['detected_entities'][:5]\n",
        "    if top_ents:\n",
        "        print(\"  Top Entities:\")\n",
        "        for ent in top_ents:\n",
        "            print(f\"    - {ent['name']} (Salience: {ent['salience']:.3f}, Type: {ent['type']})\")\n",
        "    else:\n",
        "        print(\"  No entities detected.\")\n",
        "\n",
        "# --- 6. Download the File ---\n",
        "print(f\"\\n‚¨áÔ∏è Downloading {output_filename}...\")\n",
        "files.download(output_filename)\n",
        "\n",
        "print(\"\\n‚ú® All done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "mAy4WfPBCzCi",
        "outputId": "a19bb45d-65ba-4617-a3dc-d2e53a8cf9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 1 content drafts...\n",
            "  Analyzing: /articles/ultimate-5-day-toronto-travel-guide (1/1)...\n",
            "\n",
            "‚úÖ NLP analysis complete!\n",
            "\n",
            "üéØ Created detailed results file: content_draft_analysis.json\n",
            "\n",
            "üìä Quick Summary:\n",
            "\n",
            "--- Page: /articles/ultimate-5-day-toronto-travel-guide ---\n",
            "  Top Categories:\n",
            "    - /Travel (Confidence: 97.00%)\n",
            "  Top Entities:\n",
            "    - FC Barcelona (Salience: 0.294, Type: LOCATION)\n",
            "    - AMA (Salience: 0.070, Type: ORGANIZATION)\n",
            "    - Barcelona -- Architecture & Art Awaits Nestled (Salience: 0.045, Type: ORGANIZATION)\n",
            "    - Things (Salience: 0.027, Type: OTHER)\n",
            "    - AMA Travel (Salience: 0.024, Type: OTHER)\n",
            "\n",
            "‚¨áÔ∏è Downloading content_draft_analysis.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40c2a09e-567f-4e19-9be4-1341c0c005ae\", \"content_draft_analysis.json\", 14968)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® All done!\n"
          ]
        }
      ]
    }
  ]
}